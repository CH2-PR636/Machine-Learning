# -*- coding: utf-8 -*-
"""waste-classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19J7n3T-Ow2TmBiL7sqeSMXQS00EubRL4

# Import
"""

import os
import glob
import zipfile
import random
import shutil
from shutil import copyfile
import matplotlib.pyplot as plt
from PIL import Image, ImageOps
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Ignore the warning.
import warnings
warnings.filterwarnings('ignore')

"""# Load Data"""

from google.colab import drive
import os
drive.mount('/gdrive')

# Commented out IPython magic to ensure Python compatibility.
# %cd /gdrive/MyDrive/waste

!unzip dataset.zip



"""# Image Visualization & Processing"""

# Setting up image data generators for training and validation.
# The generators apply a rescale transformation to the images and fill any gaps using the 'reflect' method.

img_train_path = os.path.join("/gdrive/MyDrive/waste/DATASET/TRAIN")
img_test_path = os.path.join("/gdrive/MyDrive/waste/DATASET/TEST")
data_gen = ImageDataGenerator(rescale=1./255, fill_mode='reflect')
val_gen = ImageDataGenerator(rescale=1./255)

train_gen = data_gen.flow_from_directory(img_train_path, target_size=(256,256), batch_size=128)
validation_gen = val_gen.flow_from_directory(img_test_path, target_size=(256,256), batch_size=128)

print("Train/Validation indicies: ", train_gen.class_indices)
print("\n0 Stands for Organic \"O\", and 1 stands for Non-Organic \"R\"")

# Plotting images from the train set.

img, _= next(train_gen)
plt.figure(figsize=(15, 13))
for i in range(30):
    ax = plt.subplot(6, 6, i + 1)
    plt.imshow(img[i])
    if _[i][1] == 0:
        plt.title("Organic")
    else:
        plt.title("Non-Organic")
    plt.axis("off")
del img
del _

model = tf.keras.Sequential()

# Add convolutional layers
model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)))
model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))
model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))
model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))
model.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu'))
model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))
model.add(tf.keras.layers.Conv2D(256, (3, 3), activation='relu'))
model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))

# Add fully-connected layers with weight decay
model.add(tf.keras.layers.Flatten())
model.add(tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.L1L2(l2=0.001)))
model.add(tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.L1L2(l2=0.001)))
model.add(tf.keras.layers.Dense(2, activation='softmax'))
model.summary()

model.compile(optimizer='Nadam',loss='CategoricalCrossentropy', metrics=['accuracy'])

# Setting up early stopping and model checkpointing to ensure we save the best model during training
# The early stopping monitor will stop training if the validation loss does not improve after 5 epochs
# The model checkpoint will save the best model based on the validation loss, and restore the best weights if training is stopped early

early_stopping_monitor = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

best_model = ModelCheckpoint('bestmodel.hdf5', monitor='val_loss', save_best_only=True)

"""# Training"""

# Compiling the model using the Nadam optimizer, categorical cross-entropy loss, and accuracy metric

history = model.fit(train_gen, validation_data=validation_gen, epochs=30, callbacks=[best_model, early_stopping_monitor])

# Plotting the training and validation accuracy over the epochs
# The figure size is set to [10,6] and the accuracy is plotted for both the training and validation sets
# A legend is added to the plot to distinguish between the two sets, and the plot is then displayed using plt.show()

plt.figure(figsize=[10,6])
plt.plot(history.history["accuracy"], label = "Train acc")
plt.plot(history.history["val_accuracy"], label = "Validation acc")
plt.legend()
plt.show()

# Plotting the training and validation loss over the epochs
# The figure size is set to (10,6) and the loss is plotted for both the training and validation sets
# A legend is added to the plot to distinguish between the two sets, and the plot is then displayed using plt.show()

plt.figure(figsize=(10,6))
plt.plot(history.history['loss'], label = "Train loss")
plt.plot(history.history['val_loss'], label = "Validation loss")
plt.legend()
plt.show()

"""# Testing"""

# Loading the weights of the best model, as determined by the model checkpoint during training
# Evaluating the model on the validation generator, and printing the evaluation metrics

model.load_weights('bestmodel.hdf5')
model.evaluate(validation_gen);

# Defining a function to predict the class of an input image using the model
# The function takes an image as input and returns the model's prediction for the class of the image

def predict_func(img):
    result = model.predict(img)
    return result

# Visualizing the model's predictions on a batch of validation images
# The figure size is set to (15, 13) and 30 images are plotted in a grid layout
# The model's prediction for each image is obtained using model.predict, and the true label of the image is obtained from the validation generator
# The title of each image shows the model's prediction, and is colored green if the prediction is correct, or red if the prediction is incorrect
# The axis of each image is turned off to focus on the image itself

img, _= next(validation_gen)
plt.figure(figsize=(15, 13))
result = model.predict(img)
for i in range(30):
    ax = plt.subplot(6, 6, i + 1)
    plt.imshow(img[i])
    if result[i][1] < 0.5:
        pred = 0
        if pred == _[i][1]:
            plt.title("Organic", color='green')
        else:
            plt.title("Organic", color='red')
    else:
        pred = 1
        if pred == _[i][1]:
            plt.title("Non-Organic", color='green')
        else:
            plt.title("Non-Organic", color='red')
    plt.axis("off")

model.save('model.h5')

